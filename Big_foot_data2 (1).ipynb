{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-15e6586b36cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"R:\\JoePriceResearch\\Python\\Anaconda3\\pkgs\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"R:\\JoePriceResearch\\Python\\Anaconda3\\pkgs\")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir(r\"C:\\Users\\josephwy\\Documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bigfoot Sightings Data\n",
    "\n",
    "I found a dataset that includes roughly 5000 bigfoot sightings from around the United States on https://data.world/timothyrenner/bfro-sightings-data. I downloaded it in a json format. \n",
    "\n",
    "\n",
    "## Upload Data\n",
    "\n",
    "When I tried to upload the data, I was met with the following error: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(r\"bfro_reports.json\", \"r\") as f:\n",
    "    bf_data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incomplete Json\n",
    "\n",
    "I spent quite a bit of time trying to determine the nature of the problem. After some research and inspection of the file, I found that it was not in proper json format. The file was lacking brackets around the data, and commas between each braced region. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repair Json file\n",
    "\n",
    "I wrote the following code to repair the data. I first saved the json as a text file. \n",
    "The code iterates line by line through the dataset, adding commas to seperate braced regions.\n",
    "It then saves the document as a json. \n",
    "I then manually added brackets to the beginning and end of the json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(r\"bfro_reports.txt\", \"r+\") as f:\n",
    "    mylist= list(f)\n",
    "    newlist = []\n",
    "    for line in mylist:\n",
    "        line = line.strip() + \",\"\n",
    "        print(line)\n",
    "        newlist.append(line)\n",
    "    f = str().join(newlist)\n",
    "    with open(r\"big_foot_data.json\", \"w\") as bf:\n",
    "        bf.write(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Round Two\n",
    "\n",
    "It worked this time! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(r\"big_foot_data.json\", \"r\") as f:      \n",
    "    bf_data = json.load(f)\n",
    "    bf_df = pd.DataFrame(bf_data)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " print(bf_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information of Interest\n",
    "\n",
    "After scanning through the data, I decided that the most valuable information would be the locations and dates of the sightings. I did't have the time or the interest to read all of the first hand accounts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(bf_df.groupby('STATE').count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bf_df[\"STATE\"].value_counts()\n",
    "print(len(bf_df[\"STATE\"].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## States Data in good shape\n",
    "\n",
    "The states data all seemed pretty standardized and reasonable-- there were 49 states listed. This was pretty fortunate. \n",
    "Unfortunately, the Year data was a mess. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bf_df[\"YEAR\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the YEAR Data\n",
    "\n",
    "There were 2 problems with the year data:\n",
    "1. It was far from standardized and incredibly messy.\n",
    "2. It was in string format and therefore difficult to treat chronologically\n",
    "\n",
    "I decided to use regular expressions to replace all of the unusual dates I found. \n",
    "At the onset it seemed most efficient to just address each variation (such as \"85-present\") individually. I used the replace command and wrote verbatim regular expressions to match them. This proved to be a miserable experience and took far longer than I anticipated. I should have written a more general code. In any case, my regex replacement is shown below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cleanup YEAR \n",
    "#In cases where multiple dates are listed, I replace with the earliest.\n",
    "#In the case of an ambiguous range, I replaced with the average\n",
    "bf_df[\"YEAR\"].replace(regex={r\"^2000-2003\" : \"2002\", \"^1977 or 78\": \"1977\",\n",
    "     \"^1977 or 78$\": \"1977\", \"^97-98$\": \"1977\", \"^mid 80's$\": \"1985\", \n",
    "     \"^\\'01or \\'02$\": \"2002\", \"^1980-1999$\": \"1990\", \"^04-05$\": \"2004\",\n",
    "     \"^1997/1998$\": \"1997\", \"^95-96$\": \"1995\", \"^1991/1999$\": \"1991\", \n",
    "     \"^1947/48$\": \"1947\", \"In the 1980's$\": \"1985\", \"^1988-1989$\" : \"1988\",\n",
    "     \"^92 or 93$\": \"1992\", \"1986- 2008$\" : \"1997\", \"^1980-82$\" : \"1981\",\n",
    "     \"^1971 or 72$\" : \"1971\", \"2012`$\" : \"2012\", \"^Late1960's$\" : \"1968\", \n",
    "     \"^1956 or 1957$\" : \"1956\", \"^1987-88$\" : \"1987\", \"^1991-92$\" : \"1991\",\n",
    "     \"^1974-1976$\" : \"1975\", \"^1984?$\" : \"1984\", \"^near 1983$\" : \"1983\", \n",
    "     \"^about 1960$\" : \"1960\", \"1976-1978$\" : \"1977\", \"^1981, 1982$\" : \"1981\",\n",
    "     \"^Late 70s$\" : \"1978\", \"79, 80, 99$\" : \"1980\", r\"93/95$\" : \"1993\", \n",
    "     \"^1985 - '87$\" : \"1986\", \"72 or 73$\" : \"1972\", \"^1971-72$\" : \"1971\",\n",
    "     \"^1998 or 19$\" : \"1998\", \"^1989?$\" : \"1989\", \"^Early 1980s$\" : \"^1980\",\n",
    "     \"^1994-1997+\" : \"1994\", \"^198945/86$\" : \"1989\", \"^1994+\" : \"1994\", \n",
    "     \"^198941, 1982$\" : \"1982\", \"^1978-1990$\" : \"1978\", \"^2014-2016\" : \"2014\",\n",
    "     r\"^198943/2010\" : \"1989\", \"^2005 2009\" : \"2005\", \"^198949 &2005\" : \"1989\",\n",
    "     \"^1973 or 74\" : \"1973\", \"^1992-3\" : \"1992\", \"^1970-1972\" : \"1970\", \n",
    "     \"^Early 1990's\" : \"1992\", \"^198949\" : \"1989\", \"^198947\" : \"1989\", \n",
    "     \"^1978 thru 1982\" : \"1978\", \"^1973-'76\" : \"1973\", \"^19894[\\d]\" : \"1989\", \n",
    "     \"^app. 1985\" : \"1985\", \"^2004-2005\" : \"2004\", \"^1959 or 60\" : \"1959\", \n",
    "     \"^1978-79\" : \"1978\", \"^2010/2011\" : \"2010\", \"^2008/2009\" : \"2008\", \n",
    "     r\"^1/5/1998\" : \"1998\", \"^1990 appro\" : \"1990\", \"^2005-06\" : \"2005\", \n",
    "     \"^2009-2010\" : \"2009\", \"^93-98\" : \"1993\", \"^71' or 72'\" : \"1971\", \n",
    "     \"^1930's\" : \"1930\", \"^1994\\?\" : \"1994\", \"^1976 or 77\" : \"1976\", \"mid 1970's\" : \"1970\", \n",
    "     \"^Late 1980s\" : \"1988\", \"^1994[\\d]+\" : \"1994\", \"^1961 1962\" : \"1961\",\n",
    "     \"^1952 or 1953\" : \"1952\", \"^1976-2000-2008\" : \"1976\", \"^1989-86\" : \"1989\",\n",
    "     \"^1979 or 80\" : \"1979\", \"^2000/2001\" : \"2000\", \"^93\" : \"1993\",\n",
    "     \"^2000-2001\" : \"2000\", \"^1989,19943\" : \"1989\", \"^2001-2004\" : \"2001\",\n",
    "     \"^07\" : \"2007\", \"^2002-2003\" : \"2002\", \"^119930\" : \"1993\",\n",
    "     \"^119191919932\" : \"1993\", \"^202020202007\" : \"2007\", \"^119191919930\" : \"1993\",\n",
    "     \"^1919191993\" : \"1993\", \"^2020202007\" : \"2007\", \"^1989 or '86\" : \"1989\",\n",
    "     \"^11919930\" : \"1993\", \"^191993\" : \"1993\", \"^1970's-1980's\" : \"1970\", \n",
    "     \"^1994-2001\" : \"1994\", \"^1989 or 1987?\" : \"1987\", \n",
    "     \"^11919932\" : \"1993\", \"^191993\" : \"1993\", \"^1978 to 1980\" : \"1978\", \n",
    "     \"^est mid-70\" : \"1975\", \n",
    "     \"^About 1977\" : \"1977\", \"^\" : \"\", \"^\" : \"\", \"^\" : \"\", \n",
    "     \"^\" : \"\", \"^\" : \"\", \"^\" : \"\", \"^\" : \"\", \n",
    "     \"^\" : \"\", \"^\" : \"\", \"^\" : \"\", \"^\" : \"\", \n",
    "     \"^\" : \"\", \"^\" : \"\", \"^\" : \"\", \"^\" : \"\",  }, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Progress Check\n",
    "\n",
    "I tried to see how many of the 400+ unique \"YEAR\" listings had been whittled down by my \n",
    "superhuman efforts. You can imagine my frustration to see the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(bf_df[\"YEAR\"].unique())\n",
    "print(len(bf_df[\"YEAR\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(bf_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desperate times call for desperate measures\n",
    "\n",
    "I was beyond jaded to find that I had only eliminated 100 of the faulty years.\n",
    "In a fit of rage, I wrote the following code: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bf_df = bf_df.dropna(subset=[\"YEAR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "good_years = \"^[\\d]{4}$\"\n",
    "bf_df = bf_df[bf_df[\"YEAR\"].str.match(good_years)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(bf_df[\"YEAR\"].unique())\n",
    "print(len(bf_df[\"YEAR\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bf_df[\"YEAR\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(bf_df.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YEAR Cleaning Continued\n",
    "\n",
    "At the expense of roughly 800 entries (which is admittedly nontrivial, but also not as bad as wasting 4 more hours on bigfoot data cleaning,) I managed to clear out all those nasty YEAR entries. I rationalized that because their misentry was quasi-random and I still had plenty of other entries, this was an acceptable cleaning method. \n",
    "\n",
    "Then I converted the years into integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bf_df[['YEAR']] = bf_df[['YEAR']].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify that they were in fact integers, I took maxes and mins:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(bf_df[\"YEAR\"].max())\n",
    "print(bf_df[\"YEAR\"].min())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization\n",
    "\n",
    "Then I wanted to visualize bigfoot sightings by state per year. The first scatterplot was illegible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "ax = sns.swarmplot(x=\"STATE\", y=\"YEAR\", data=bf_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I decided to group the states by US Census Regions: Northeast, Midwest, South, and West. I did so by creating my own dataframe to merge with the bigfoot one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(r\"state_region.csv\", \"r\") as j:\n",
    "    state_df = pd.read_csv(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bf_df = bf_df.merge(state_df, left_on='STATE', right_on='STATE', how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the merge complete, I then played around with some new graphs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(12,9)})\n",
    "ax = sns.swarmplot(x=\"REGION\", y=\"YEAR\", data=bf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(15,12)})\n",
    "ax = sns.violinplot(x=\"REGION\", y=\"YEAR\", data=bf_df, inner=None)\n",
    "ax = sns.swarmplot(x=\"REGION\", y=\"YEAR\", data=bf_df,color=\"white\", edgecolor=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(bf_df[\"REGION\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(bf_df[\"YEAR\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions:\n",
    "\n",
    "The Pacific is a hotspot for bigfoot sightings. I'm certain that he spent some time in the region, likely within the last 18 years. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alchohol Consumption by State\n",
    "\n",
    "I found the following data in a Washington Post article:\n",
    "https://www.washingtonpost.com/news/wonk/wp/2016/12/24/where-the-heaviest-drinking-americans-live/?noredirect=on&utm_term=.4070d0f562d6\n",
    "\n",
    "It gives the average monthly drinking rate per state for the years 2008-2009 and 2014-2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the Data\n",
    "\n",
    "I scraped in the data from the Washington post website and parsed it using BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "site_text = requests.get(\"https://www.washingtonpost.com/news/wonk/wp/2016/12/24/where-the-heaviest-drinking-americans-live/?noredirect=on&utm_term=.4070d0f562d6\").text\n",
    "soup = BeautifulSoup(site_text, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the prettified file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabulating the Data\n",
    "\n",
    "I tabulated the data using the pandas read_html function. It came out very nicely:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alchohol_table = soup.find_all('table')[0]     \n",
    "alch_df = pd.read_html(str(alchohol_table))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(alch_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is very clean and simple and doesn't require any further preparation. For this reason, I played with it in some other ways. \n",
    "\n",
    "First, I renamed the column labels, since they are so lengthy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alch_df = alch_df.rename(index=str, columns={\"Monthly drinking rate, 2008-2009\": \"Drinking_Rate_08-09\", \"Monthly drinking rate, 2014-2015\": \"Drinking_Rate_14-15\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list(alch_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I created a new variable that is the average of the drinking rates over the two periods (2008-2009 and 2014-2015). \n",
    "This way I have a more general drinking rate per state. \n",
    "\n",
    "In order to do so, I had to change the column type to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alch_df[['Drinking_Rate_08-09']] = alch_df[['Drinking_Rate_08-09']].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alch_df['Avg_Drinking_Rate'] = (alch_df[\"Drinking_Rate_08-09\"] + alch_df[\"Drinking_Rate_14-15\"])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alch_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alch_df = alch_df.merge(state_df, left_on='State', right_on='STATE', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bx = sns.swarmplot(x=\"State\", y=\"Avg_Drinking_Rate\", data=alch_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the plot is pretty illegible due to the large number of states. Good thing I still had my State_region csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alch_df = alch_df.merge(state_df, left_on='State', right_on='STATE', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alch_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bx = sns.swarmplot(x=\"REGION_x\", y=\"Avg_Drinking_Rate\", data=alch_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bf_df = bf_df.merge(alch_df, left_on='STATE', right_on='STATE_x', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cx = sns.swarmplot(x=\"REGION_x\", y=\"Avg_Drinking_Rate\", data=alch_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bf_df['freq'] = bf_df.groupby('STATE')['STATE'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bf_df['freq'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dx = sns.swarmplot(x=\"freq\", y=\"Avg_Drinking_Rate\", data=bf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
